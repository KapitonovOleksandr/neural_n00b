{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  YOLO (You Only Look Once)\n",
    "\n",
    "The main idea behind YOLO is to perform object detection in a single pass through the neural network, which involves predicting bounding boxes and class probabilities directly from the image pixels. This approach is in contrast to methods that first propose candidate regions and then classify each region separately.\n",
    "\n",
    "\n",
    "### YOLO the main component\n",
    "\n",
    "**Backbone:** YOLOv4 uses CSPDarknet53 as its feature extractor or backbone network. This backbone is responsible for ***extracting features from the input image.*** CSP stands for Cross Stage Partial networks, which help in ***reducing*** the computation ***cost*** while maintaining ***accuracy.***\n",
    "\n",
    "**Neck:** The neck is composed of the Path Aggregation Network (PANet) and Spatial Pyramid Pooling (SPP) block. The PANet aids in the aggregation of different levels of features which are beneficial for detecting objects at various scales. The SPP block increases the receptive field and helps to separate out the most significant context features.\n",
    "\n",
    "**Head:** The head of YOLOv4 performs the ***detection tasks.*** It consists of YOLO layers that ***predict bounding boxes***, objectness scores (the ***likelihood*** that a box contains an object), and class predictions. The head processes the feature maps at three different scales, which allows it to detect small, medium, and large objects.\n",
    "\n",
    "**Anchor Boxes:** YOLOv4 uses anchor boxes, which are **predefined bounding boxes** that the model uses as a starting point for predicting actual bounding boxes around objects.\n",
    "\n",
    "\n",
    "<img src=\"./img/comp_vision/YOLOV_architecture.png\" alt=\"nearby_objects\" width=\"900\"/>\n",
    "\n",
    "### YOLO Architecture\n",
    "\n",
    "- **Residual Blocks:** These are likely components that help in training deep networks by allowing gradients to flow through the network **without vanishing or exploding.** They usually consist of convolutional layers with **skip connections.**\n",
    "\n",
    "- **Detection Layers:** These are the layers where the **actual prediction of bounding boxes** and class probabilities occurs.\n",
    "\n",
    "- **Upsampling Layers:** These layers increase the **spatial resolution of the feature maps**, which allows the network to detect smaller objects.\n",
    "\n",
    "- **Concatenation and Addition:** These operations are used to **combine feature maps**. Concatenation merges feature maps along the channel dimension, preserving all features, while addition is a way to **merge feature maps by element-wise addition**, which can be part of a residual learning strategy.\n",
    "\n",
    "- **Further Layers:** The dots leading to further layers imply that the network architecture extends beyond what is shown, likely for additional processing or to handle different scales of detection.\n",
    "\n",
    "- **Scale 1, Scale 2, Scale 3:** These are likely referring to the multi-scale predictions that YOLO networks perform. Different scales allow the detection of objects of various sizes. The stride indicates the factor by which the image is downsampled; a larger stride results in a smaller feature map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO Deploy on embedding devices. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nn_n00b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
