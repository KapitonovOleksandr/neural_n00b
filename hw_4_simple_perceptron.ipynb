{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 4. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4.1: \n",
    "\n",
    "# Handwritten Digits Classification\n",
    "\n",
    "## Overview\n",
    "Implementing a Neural Network for classifying handwritten digits using the 3D MNIST dataset, with a focus on PyTorch for model development and accuracy assessment.\n",
    "\n",
    "### Dataset\n",
    "- Utilize the [3D MNIST dataset from Kaggle](https://www.kaggle.com/datasets/daavoo/3d-mnist) for training and testing the model.\n",
    "\n",
    "### Neural Network Implementation with PyTorch\n",
    "- Implement a Neural Network using PyTorch. \n",
    "- Ensure the network is suitable for handling the 3D data structure of the dataset.\n",
    "- Tailor the architecture to effectively learn from the dataset for digit classification.\n",
    "\n",
    "### Accuracy Calculation\n",
    "- After training, evaluate the model on a test set.\n",
    "- Calculate the accuracy of the model: $$\\frac{\\text{Number of Correct Predictions}}{\\text{Total Predictions}}$$\n",
    "- Document the model's performance and any insights gained during the development process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchinfo\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X_test', 'X_train', 'y_test', 'y_train']\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('data/3d_mnist/full_dataset_vectors.h5', 'r') as file:\n",
    "    datasets_names = list(file.keys())\n",
    "    print(datasets_names)\n",
    "    X_train, y_train, X_test, y_test = file['X_train'][:], file['y_train'][:], file['X_test'][:], file['y_test'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " array([5, 5, 0, ..., 1, 2, 2], dtype=int64))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at data\n",
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec 10 16:05:40 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 546.29                 Driver Version: 546.29       CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1050 Ti   WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   55C    P8              N/A / ERR! |   1946MiB /  4096MiB |     18%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2128      C   ...rograms\\Python\\Python311\\python.exe    N/A      |\n",
      "|    0   N/A  N/A      3604      C   ...rograms\\Python\\Python311\\python.exe    N/A      |\n",
      "|    0   N/A  N/A      7076      C   ...rograms\\Python\\Python311\\python.exe    N/A      |\n",
      "|    0   N/A  N/A      9692      C   ...rograms\\Python\\Python311\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     10284      C   ...rograms\\Python\\Python311\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     10736      C   ...rograms\\Python\\Python311\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     10780    C+G   ...8.0_x64__t4vj0pshhgkwm\\Telegram.exe    N/A      |\n",
      "|    0   N/A  N/A     10792      C   ...rograms\\Python\\Python311\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     14156      C   ...rograms\\Python\\Python311\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     19788      C   ...rograms\\Python\\Python311\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     19796      C   ...rograms\\Python\\Python311\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     20420      C   ...rograms\\Python\\Python311\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     27348      C   ...rograms\\Python\\Python311\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     27644      C   ...rograms\\Python\\Python311\\python.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "NVIDIA GeForce GTX 1050 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Print the number of available GPUs\n",
    "    print(torch.cuda.device_count())\n",
    "    # Print the current GPU device\n",
    "    print(torch.cuda.current_device())\n",
    "    # Print the name of the GPU\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA is not available. Check your GPU drivers and CUDA installation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 4096), (2000, 4096), (10000,), (2000,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shapes\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (10000, 4096, 3)\n",
      "X_test shape: (2000, 4096, 3)\n"
     ]
    }
   ],
   "source": [
    "# Add color channels to pics\n",
    "s_m = plt.cm.ScalarMappable()\n",
    "X_train = s_m.to_rgba(X_train)[:,:,:-1]\n",
    "X_test = s_m.to_rgba(X_test)[:,:,:-1]\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.267004, 0.004874, 0.329415],\n",
       "       [0.267004, 0.004874, 0.329415],\n",
       "       [0.267004, 0.004874, 0.329415],\n",
       "       ...,\n",
       "       [0.267004, 0.004874, 0.329415],\n",
       "       [0.267004, 0.004874, 0.329415],\n",
       "       [0.267004, 0.004874, 0.329415]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View observation\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape \n",
    "class ReshapeT:\n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return torch.tensor(x.reshape(self.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms \n",
    "transformer = v2.Compose([\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    ReshapeT((3, 16, 16, 16))\n",
    "])\n",
    "\n",
    "label_transformer = v2.Compose([\n",
    "    v2.ToDtype(torch.float32, scale=False)\n",
    "])\n",
    "\n",
    "# # Custom Dataset\n",
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(self, data, labels, transform=False, label_transform=False):\n",
    "#         self.data = data\n",
    "#         self.labels = labels\n",
    "#         self.transform = transform\n",
    "#         self.label_transform = label_transform\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.labels)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         image = self.data[idx]\n",
    "#         label = self.labels[idx]\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "#         if self.label_transform:\n",
    "#             label = self.label_transform(label)\n",
    "#         return torch.Tensor(image), torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "X_train = torch.tensor(X_train.reshape((len(X_train), 3, 16, 16, 16)), dtype=torch.float32).to(device)\n",
    "X_test = torch.tensor(X_test.reshape((len(X_test), 3, 16, 16, 16)), dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train).to(device)\n",
    "y_test = torch.tensor(y_test).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "# Datasets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.5756],\n",
       "           [0.8446, 0.2564, 0.5756,  ..., 0.2564, 0.5756, 0.8446],\n",
       "           [0.2564, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           ...,\n",
       "           [0.7740, 0.4066, 0.1312,  ..., 0.5525, 0.3278, 0.7740],\n",
       "           [0.4066, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.1579]],\n",
       " \n",
       "          [[0.6838, 0.5017, 0.1563,  ..., 0.5579, 0.1579, 0.6838],\n",
       "           [0.5017, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.1579],\n",
       "           ...,\n",
       "           [0.3294, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.2670],\n",
       "           [0.0049, 0.3294, 0.2670,  ..., 0.3294, 0.2670, 0.0049]],\n",
       " \n",
       "          [[0.3294, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.2670],\n",
       "           [0.0049, 0.3294, 0.2670,  ..., 0.3294, 0.2670, 0.0049],\n",
       "           ...,\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.2670],\n",
       "           [0.0049, 0.3294, 0.2670,  ..., 0.3294, 0.2670, 0.0049],\n",
       "           [0.3294, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.3515, 0.5506, 0.1563,  ..., 0.5579, 0.2162, 0.3515],\n",
       "           [0.5506, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.1579],\n",
       "           ...,\n",
       "           [0.5525, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.1312],\n",
       "           [0.5559, 0.5525, 0.2670,  ..., 0.3294, 0.1312, 0.5559]],\n",
       " \n",
       "          [[0.5525, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.1579],\n",
       "           [0.6838, 0.5017, 0.2762,  ..., 0.4930, 0.1579, 0.6838],\n",
       "           ...,\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.2670],\n",
       "           [0.0049, 0.3294, 0.2670,  ..., 0.3294, 0.2670, 0.0049],\n",
       "           [0.3294, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294]],\n",
       " \n",
       "          [[0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.2670],\n",
       "           [0.0049, 0.3294, 0.2670,  ..., 0.3294, 0.2670, 0.0049],\n",
       "           [0.3294, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           ...,\n",
       "           [0.0049, 0.3294, 0.2670,  ..., 0.3294, 0.2670, 0.0049],\n",
       "           [0.3294, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.2670]]],\n",
       " \n",
       " \n",
       "         [[[0.0049, 0.3294, 0.2670,  ..., 0.3294, 0.2670, 0.0049],\n",
       "           [0.3294, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.2670],\n",
       "           ...,\n",
       "           [0.5525, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.1254],\n",
       "           [0.5743, 0.5491, 0.2162,  ..., 0.5506, 0.1254, 0.5743]],\n",
       " \n",
       "          [[0.5491, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.1312],\n",
       "           [0.5559, 0.5525, 0.2670,  ..., 0.3294, 0.1312, 0.5559],\n",
       "           ...,\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.2670],\n",
       "           [0.0049, 0.3294, 0.2670,  ..., 0.3294, 0.2670, 0.0049],\n",
       "           [0.3294, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294]],\n",
       " \n",
       "          [[0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.2670],\n",
       "           [0.0049, 0.3294, 0.2670,  ..., 0.3294, 0.2670, 0.0049],\n",
       "           [0.3294, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           ...,\n",
       "           [0.0049, 0.3294, 0.2670,  ..., 0.3294, 0.2670, 0.0049],\n",
       "           [0.3294, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.2670]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.5579, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.2651],\n",
       "           [0.2330, 0.5166, 0.2162,  ..., 0.5506, 0.2651, 0.2330],\n",
       "           ...,\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.2670],\n",
       "           [0.0049, 0.3294, 0.2670,  ..., 0.3294, 0.2670, 0.0049],\n",
       "           [0.3294, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294]],\n",
       " \n",
       "          [[0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.2670],\n",
       "           [0.0049, 0.3294, 0.2670,  ..., 0.3294, 0.2670, 0.0049],\n",
       "           [0.3294, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           ...,\n",
       "           [0.0049, 0.3294, 0.2670,  ..., 0.3294, 0.2670, 0.0049],\n",
       "           [0.3294, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.1839]],\n",
       " \n",
       "          [[0.4224, 0.5569, 0.1563,  ..., 0.5579, 0.1839, 0.4224],\n",
       "           [0.5569, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.1563],\n",
       "           ...,\n",
       "           [0.3294, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.2670],\n",
       "           [0.0049, 0.3294, 0.2670,  ..., 0.3294, 0.2670, 0.0049]]],\n",
       " \n",
       " \n",
       "         [[[0.3294, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.2670],\n",
       "           [0.0049, 0.3294, 0.2670,  ..., 0.3294, 0.2670, 0.0049],\n",
       "           ...,\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.2670],\n",
       "           [0.0049, 0.3294, 0.2670,  ..., 0.3294, 0.2670, 0.0049],\n",
       "           [0.3294, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294]],\n",
       " \n",
       "          [[0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.2670],\n",
       "           [0.0049, 0.3294, 0.2670,  ..., 0.3294, 0.2670, 0.0049],\n",
       "           [0.3294, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           ...,\n",
       "           [0.8507, 0.2367, 0.5756,  ..., 0.2564, 0.6060, 0.8507],\n",
       "           [0.2367, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.1466]],\n",
       " \n",
       "          [[0.6730, 0.5089, 0.1839,  ..., 0.5569, 0.1466, 0.6730],\n",
       "           [0.5089, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.1312],\n",
       "           ...,\n",
       "           [0.5166, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.2162],\n",
       "           [0.3515, 0.5506, 0.1563,  ..., 0.5579, 0.2162, 0.3515]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.2670],\n",
       "           [0.0049, 0.3294, 0.2670,  ..., 0.3294, 0.2670, 0.0049],\n",
       "           [0.3294, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           ...,\n",
       "           [0.3993, 0.5556, 0.1312,  ..., 0.5525, 0.1941, 0.3993],\n",
       "           [0.5556, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.2162]],\n",
       " \n",
       "          [[0.3515, 0.5506, 0.1563,  ..., 0.5579, 0.2162, 0.3515],\n",
       "           [0.5506, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.1579],\n",
       "           ...,\n",
       "           [0.5017, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.1579],\n",
       "           [0.6838, 0.5017, 0.1563,  ..., 0.5579, 0.1579, 0.6838]],\n",
       " \n",
       "          [[0.5017, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294],\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.3278],\n",
       "           [0.7740, 0.4066, 0.1312,  ..., 0.5525, 0.3278, 0.7740],\n",
       "           ...,\n",
       "           [0.2670, 0.0049, 0.3294,  ..., 0.0049, 0.3294, 0.5756],\n",
       "           [0.8446, 0.2564, 0.5756,  ..., 0.2564, 0.5756, 0.8446],\n",
       "           [0.2564, 0.2670, 0.0049,  ..., 0.2670, 0.0049, 0.3294]]]],\n",
       "        device='cuda:0'),\n",
       " tensor(5, device='cuda:0'))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View dataset item\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at sample\n",
    "# next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN architecture\n",
    "class Convolutional_3d(nn.Module):\n",
    "    def __init__(self, input_layers, hidden_layers, output_layers, number_of_class=0):\n",
    "        super(Convolutional_3d, self).__init__()\n",
    "        self.conv3d_block_1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=input_layers, out_channels=hidden_layers, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(in_channels=hidden_layers, out_channels=hidden_layers, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=3, stride=1)\n",
    "        )\n",
    "        \n",
    "        self.conv3d_block_2 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=hidden_layers, out_channels=hidden_layers, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(in_channels=hidden_layers, out_channels=hidden_layers, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=3, stride=1)\n",
    "        )\n",
    "        \n",
    "        self.classifier_block = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=55296, out_features=output_layers), # 55296 a number taken from a shape error.\n",
    "            nn.Softmax()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        l = self.conv3d_block_1(x)\n",
    "        l = self.conv3d_block_2(l)\n",
    "        l = self.classifier_block(l)\n",
    "        return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = Convolutional_3d(input_layers=3,\n",
    "                           hidden_layers=32,\n",
    "                           output_layers=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Convolutional_3d(\n",
       "  (conv3d_block_1): Sequential(\n",
       "    (0): Conv3d(3, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool3d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3d_block_2): Sequential(\n",
       "    (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool3d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier_block): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=55296, out_features=10, bias=True)\n",
       "    (2): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Convolutional_3d                         --\n",
       "├─Sequential: 1-1                        --\n",
       "│    └─Conv3d: 2-1                       2,624\n",
       "│    └─ReLU: 2-2                         --\n",
       "│    └─Conv3d: 2-3                       27,680\n",
       "│    └─ReLU: 2-4                         --\n",
       "│    └─MaxPool3d: 2-5                    --\n",
       "├─Sequential: 1-2                        --\n",
       "│    └─Conv3d: 2-6                       27,680\n",
       "│    └─ReLU: 2-7                         --\n",
       "│    └─Conv3d: 2-8                       27,680\n",
       "│    └─ReLU: 2-9                         --\n",
       "│    └─MaxPool3d: 2-10                   --\n",
       "├─Sequential: 1-3                        --\n",
       "│    └─Flatten: 2-11                     --\n",
       "│    └─Linear: 2-12                      552,970\n",
       "│    └─Softmax: 2-13                     --\n",
       "=================================================================\n",
       "Total params: 638,634\n",
       "Trainable params: 638,634\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(model_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "LR = 0.05\n",
    "OPTIMIZER = torch.optim.Adam(params=model_0.parameters(), lr=LR)\n",
    "LOSS_FUNC = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:22<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 8252, 19108, 26172, 19396, 18912, 26452, 8704, 4828, 16052) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Sanya\\kapitonnov_nn_n00b\\neural_n00b\\nn_n00b_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m   1133\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll(timeout):\n\u001b[1;32m--> 114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Sanya\\kapitonnov_nn_n00b\\neural_n00b\\hw_4_simple_perceptron.ipynb Cell 23\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sanya/kapitonnov_nn_n00b/neural_n00b/hw_4_simple_perceptron.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(EPOCHS)):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sanya/kapitonnov_nn_n00b/neural_n00b/hw_4_simple_perceptron.ipynb#X33sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------------------------------------------------------------------------\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Sanya/kapitonnov_nn_n00b/neural_n00b/hw_4_simple_perceptron.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m batch, (image, label) \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(train_dataloader, start\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sanya/kapitonnov_nn_n00b/neural_n00b/hw_4_simple_perceptron.ipynb#X33sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         logits \u001b[39m=\u001b[39;49m model_0(image)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sanya/kapitonnov_nn_n00b/neural_n00b/hw_4_simple_perceptron.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         loss \u001b[39m=\u001b[39;49m LOSS_FUNC(logits, label)\n",
      "File \u001b[1;32mc:\\Users\\Sanya\\kapitonnov_nn_n00b\\neural_n00b\\nn_n00b_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Sanya\\kapitonnov_nn_n00b\\neural_n00b\\nn_n00b_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[0;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[0;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[0;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Sanya\\kapitonnov_nn_n00b\\neural_n00b\\nn_n00b_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1290\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1293\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m-> 1294\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[0;32m   1295\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m   1296\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Sanya\\kapitonnov_nn_n00b\\neural_n00b\\nn_n00b_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1145\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(failed_workers) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1144\u001b[0m     pids_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(w\u001b[39m.\u001b[39mpid) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1145\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDataLoader worker (pid(s) \u001b[39m\u001b[39m{\u001b[39;00mpids_str\u001b[39m}\u001b[39;00m\u001b[39m) exited unexpectedly\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, queue\u001b[39m.\u001b[39mEmpty):\n\u001b[0;32m   1147\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 8252, 19108, 26172, 19396, 18912, 26452, 8704, 4828, 16052) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "model_0.train()\n",
    "print('TRAINING...')\n",
    "train_loss, train_accuracy = 0, 0\n",
    "train_num_batches = len(train_dataloader)\n",
    "train_size = len(train_dataloader.dataset)\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    print(f'Epoch: {epoch}\\n-------------------------------------------------------------------------------')\n",
    "    for batch, (image, label) in enumerate(train_dataloader, start=1):\n",
    "        logits = model_0(image)\n",
    "        loss = LOSS_FUNC(logits, label)\n",
    "        OPTIMIZER.zero_grad()\n",
    "        loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "        train_loss += loss.item()\n",
    "        train_accuracy += (logits.argmax(1)==label).type(torch.float32).sum().item()\n",
    "    train_loss /= train_num_batches\n",
    "    train_accuracy /= train_size\n",
    "    print(f'Train Loss: {train_loss} || Train Accuracy: {train_accuracy}\\n\\n')\n",
    "print('Finished TRAINING!')\n",
    "\n",
    "# test model\n",
    "model_0.eval()\n",
    "print('TESTING...')\n",
    "test_num_batches = len(test_dataloader)\n",
    "test_size = len(test_dataloader.dataset)\n",
    "test_loss, test_accuracy = 0, 0\n",
    "with torch.inference_mode():\n",
    "    for image, label in test_dataloader:\n",
    "        pred = model_0(image)\n",
    "        loss = LOSS_FUNC(pred, label)\n",
    "        test_loss += loss.item()\n",
    "        test_accuracy += (pred.argmax(1)==label).type(torch.float32).sum().item()\n",
    "test_loss /= test_num_batches\n",
    "test_accuracy /= test_size\n",
    "print(f'Mean test Loss: {loss} || Mean test Accuracy: {test_accuracy}\\n')\n",
    "print('Finished TESTING!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
