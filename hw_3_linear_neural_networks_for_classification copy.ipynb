{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 3. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3.1: \n",
    "\n",
    "# Cat and Dog Image Classification\n",
    "\n",
    "This project involves building a binary classifier to distinguish between images of cats and dogs using logistic regression. Below are the steps followed in this project:\n",
    "\n",
    "## 1. Dataset\n",
    "- The project uses the [Cat and Dog dataset from Kaggle](https://www.kaggle.com/datasets/tongpython/cat-and-dog).\n",
    "- This dataset consists of images of cats and dogs, which are used to train and test the model for binary classification.\n",
    "\n",
    "## 2. Prepare Dataset and Train Model\n",
    "- The dataset is first preprocessed to be suitable for input into the logistic regression model. This includes resizing images, converting them to grayscale or color, and flattening them into a 1D array (if necessary).\n",
    "- We use the Logistic Regression model from the scikit-learn library. More details can be found on the [LogisticRegression documentation page](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "- The dataset is split into training and testing sets. The model is trained on the training set.\n",
    "\n",
    "## 3. Model Evaluation\n",
    "- The accuracy of the model is calculated by comparing the modelâ€™s predictions on the test set with the actual labels.\n",
    "- Accuracy is determined using the formula: $$\\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}}$$\n",
    "- This metric gives us an understanding of how well our model performs in distinguishing between images of cats and dogs.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pprint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data paths\n",
    "data_dir = Path('data')\n",
    "data_path = data_dir / 'cats_and_dogs'\n",
    "train_data_path = data_path / 'training_set\\\\training_set'\n",
    "test_data_path = data_path / 'test_set\\\\test_set'\n",
    "train_cats_path = train_data_path / 'cats'\n",
    "train_dogs_path = train_data_path / 'dogs'\n",
    "test_cats_path = test_data_path / 'cats'\n",
    "test_dogs_path = test_data_path / 'dogs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'train/test'\n",
    "train_cats = train_cats_path.glob('*.jpg')\n",
    "train_dogs = train_dogs_path.glob('*.jpg')\n",
    "test_cats = test_cats_path.glob('*.jpg')\n",
    "test_dogs = test_dogs_path.glob('*.jpg')\n",
    "\n",
    "# values of classes\n",
    "labels = {'cat': 0, 'dog': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "def preprocess(image_path: iter):\n",
    "    \"\"\"Prprocess images to a numpy array given it's path.\"\"\"\n",
    "    sizes = (40, 40)\n",
    "    image_data = []\n",
    "    for i, p in enumerate(image_path):\n",
    "        if i == 5:\n",
    "            break\n",
    "        with Image.open(p) as image:\n",
    "            image = image.resize(sizes)\n",
    "            image_data.append(np.array(image).flatten()/255.0)\n",
    "    return np.array(image_data)\n",
    "\n",
    "def create_dataset(image_path: iter, label:int=0, test: bool=False):\n",
    "    \"\"\"Create a dataset from images in the specified directory.\"\"\"\n",
    "    image_processed = preprocess(image_path)\n",
    "    if test:\n",
    "        return image_processed\n",
    "    dummy_array = np.zeros((len(image_processed))).reshape((-1, 1))\n",
    "    labels = np.full_like(dummy_array, label)\n",
    "    return np.hstack((image_processed, labels))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cats train data:\n",
      " [[0.15294118 0.16862745 0.17647059 ... 0.16862745 0.14901961 0.        ]\n",
      " [0.15294118 0.18823529 0.21568627 ... 0.72941176 0.02352941 0.        ]\n",
      " [0.87058824 0.8745098  0.85490196 ... 0.83529412 0.81960784 0.        ]\n",
      " [0.49803922 0.39215686 0.25098039 ... 0.3254902  0.21960784 0.        ]\n",
      " [0.21960784 0.18039216 0.05490196 ... 0.56470588 0.36078431 0.        ]] \n",
      "\n",
      "Dogs train data:\n",
      " [[0.56470588 0.41568627 0.29019608 ... 0.92941176 0.84705882 1.        ]\n",
      " [0.50196078 0.37254902 0.17647059 ... 0.36862745 0.31764706 1.        ]\n",
      " [0.75686275 0.71372549 0.69019608 ... 0.25098039 0.21176471 1.        ]\n",
      " [0.09411765 0.06666667 0.0627451  ... 0.43921569 0.40392157 1.        ]\n",
      " [0.5372549  0.52156863 0.47843137 ... 0.58039216 0.57647059 1.        ]] \n",
      "\n",
      "Shuffled train data:\n",
      " [[0.75686275 0.71372549 0.69019608 ... 0.25098039 0.21176471 1.        ]\n",
      " [0.21960784 0.18039216 0.05490196 ... 0.56470588 0.36078431 0.        ]\n",
      " [0.15294118 0.18823529 0.21568627 ... 0.72941176 0.02352941 0.        ]\n",
      " [0.5372549  0.52156863 0.47843137 ... 0.58039216 0.57647059 1.        ]\n",
      " [0.15294118 0.16862745 0.17647059 ... 0.16862745 0.14901961 0.        ]] \n",
      "\n",
      "Cats test data:\n",
      " [[0.50980392 0.47843137 0.49019608 ... 0.33333333 0.34901961 0.        ]\n",
      " [0.48235294 0.4627451  0.39215686 ... 0.16470588 0.07058824 0.        ]\n",
      " [0.23529412 0.21960784 0.16862745 ... 0.5254902  0.49019608 0.        ]\n",
      " [0.46666667 0.3372549  0.24705882 ... 0.52156863 0.40392157 0.        ]\n",
      " [0.88627451 0.89411765 0.89019608 ... 0.99607843 0.89411765 0.        ]] \n",
      "\n",
      "Dogs test data:\n",
      " [[0.36078431 0.29019608 0.22745098 ... 0.54117647 0.51764706 1.        ]\n",
      " [0.09803922 0.09411765 0.08627451 ... 0.09803922 0.08627451 1.        ]\n",
      " [0.02745098 0.02745098 0.02745098 ... 0.07058824 0.0627451  1.        ]\n",
      " [0.14509804 0.14901961 0.14509804 ... 0.38039216 0.2745098  1.        ]\n",
      " [0.46666667 0.41568627 0.35294118 ... 0.52156863 0.49411765 1.        ]] \n",
      "\n",
      "Shuffled test data:\n",
      " [[0.36078431 0.29019608 0.22745098 ... 0.54117647 0.51764706 1.        ]\n",
      " [0.46666667 0.3372549  0.24705882 ... 0.52156863 0.40392157 0.        ]\n",
      " [0.09803922 0.09411765 0.08627451 ... 0.09803922 0.08627451 1.        ]\n",
      " [0.23529412 0.21960784 0.16862745 ... 0.5254902  0.49019608 0.        ]\n",
      " [0.88627451 0.89411765 0.89019608 ... 0.99607843 0.89411765 0.        ]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create our datasets\n",
    "cat_train_set = create_dataset(train_cats, label=0)\n",
    "print('Cats train data:\\n', cat_train_set[:5],'\\n')\n",
    "dog_train_set = create_dataset(train_dogs, label=1)\n",
    "print('Dogs train data:\\n', dog_train_set[:5],'\\n')\n",
    "train_dataset = np.random.permutation(np.concatenate((cat_train_set, dog_train_set)))\n",
    "print('Shuffled train data:\\n', train_dataset[:5],'\\n')\n",
    "cat_test_set = create_dataset(test_cats, label=0)\n",
    "print('Cats test data:\\n', cat_test_set[:5],'\\n')\n",
    "dog_test_set = create_dataset(test_dogs, label=1)\n",
    "print('Dogs test data:\\n', dog_test_set[:5],'\\n')\n",
    "test_dataset = np.random.permutation(np.concatenate((cat_test_set, dog_test_set)))\n",
    "print('Shuffled test data:\\n', test_dataset[:5],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      " [[0.75686275 0.71372549 0.69019608 ... 0.32156863 0.25098039 0.21176471]\n",
      " [0.21960784 0.18039216 0.05490196 ... 0.09411765 0.56470588 0.36078431]\n",
      " [0.15294118 0.18823529 0.21568627 ... 0.7372549  0.72941176 0.02352941]\n",
      " ...\n",
      " [0.50196078 0.37254902 0.17647059 ... 0.38823529 0.36862745 0.31764706]\n",
      " [0.87058824 0.8745098  0.85490196 ... 0.84705882 0.83529412 0.81960784]\n",
      " [0.56470588 0.41568627 0.29019608 ... 0.92941176 0.92941176 0.84705882]] \n",
      "\n",
      "y_train:\n",
      " [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]] \n",
      "\n",
      "X_test:\n",
      " [[0.36078431 0.29019608 0.22745098 ... 0.63529412 0.54117647 0.51764706]\n",
      " [0.46666667 0.3372549  0.24705882 ... 0.65098039 0.52156863 0.40392157]\n",
      " [0.09803922 0.09411765 0.08627451 ... 0.12156863 0.09803922 0.08627451]\n",
      " ...\n",
      " [0.50980392 0.47843137 0.49019608 ... 0.30980392 0.33333333 0.34901961]\n",
      " [0.14509804 0.14901961 0.14509804 ... 0.45490196 0.38039216 0.2745098 ]\n",
      " [0.02745098 0.02745098 0.02745098 ... 0.07843137 0.07058824 0.0627451 ]] \n",
      "\n",
      "y_test:\n",
      " [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train, y_train = train_dataset[:, :-1], train_dataset[:, -1:]\n",
    "X_test, y_test = test_dataset[:, :-1], test_dataset[:, -1:]\n",
    "print('X_train:\\n', X_train,'\\n')\n",
    "print('y_train:\\n', y_train,'\\n')\n",
    "print('X_test:\\n', X_test,'\\n')\n",
    "print('y_test:\\n', y_test,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sanya\\kapitonnov_nn_n00b\\neural_n00b\\nn_n00b_env\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "logr = LogisticRegression()\n",
    "logr.fit(X_train, y_train)\n",
    "y_pred = logr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncp = y_pred\n",
    "tnp = y_test.reshape((-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "\n",
      "('              precision    recall  f1-score   support\\n'\n",
      " '\\n'\n",
      " '         0.0       0.50      0.20      0.29         5\\n'\n",
      " '         1.0       0.50      0.80      0.62         5\\n'\n",
      " '\\n'\n",
      " '    accuracy                           0.50        10\\n'\n",
      " '   macro avg       0.50      0.50      0.45        10\\n'\n",
      " 'weighted avg       0.50      0.50      0.45        10\\n')\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "accuracy = np.sum(ncp==tnp)/len(y_test)\n",
    "cls_report = classification_report(y_pred=y_pred, y_true=y_test)\n",
    "print(f'Accuracy: {accuracy}\\n')\n",
    "pprint.pprint(cls_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
